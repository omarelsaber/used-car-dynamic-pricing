{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document key findings for the team\n",
    "findings = {\n",
    "    'total_rows': len(df),\n",
    "    'total_columns': len(df.columns),\n",
    "    'missing_columns': len(missing_data),\n",
    "    'cleaning_needed': len(cleaning_needed),\n",
    "    'duplicates': int(duplicate_count)\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ EDA Complete! Ready for data preprocessing pipeline.\")\n",
    "print(f\"Findings: {findings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb28d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìã INITIAL EDA SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Dataset Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"Duplicate Rows: {duplicate_count}\")\n",
    "print(f\"Columns with Missing Values: {len(missing_data)}\")\n",
    "print(f\"Columns Needing Cleaning: {len(cleaning_needed)}\")\n",
    "print(f\"Numerical Columns: {len(df.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"Categorical Columns: {len(categorical_cols)}\")\n",
    "\n",
    "print(\"\\nüéØ NEXT STEPS:\")\n",
    "print(\"1. Clean columns with currency symbols and unit strings (km, cc)\")\n",
    "print(\"2. Handle missing values based on domain knowledge\")\n",
    "print(\"3. Convert object columns to appropriate numeric types\")\n",
    "print(\"4. Standardize categorical variables\")\n",
    "print(\"5. Remove or investigate duplicate records\")\n",
    "print(\"6. Perform deeper statistical analysis and feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717a859",
   "metadata": {},
   "source": [
    "## 8. Summary of Findings & Next Steps\n",
    "\n",
    "Consolidate all findings and define preprocessing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_count = df.duplicated().sum()\n",
    "print(\"=\"*80)\n",
    "print(\"DUPLICATE RECORDS CHECK\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total duplicate rows: {duplicate_count}\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(f\"‚ö†Ô∏è  {duplicate_count} duplicate records found ({duplicate_count/len(df)*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"‚úÖ No duplicate records found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c860c6e6",
   "metadata": {},
   "source": [
    "## 7. Duplicate Records Check\n",
    "\n",
    "Identify and report duplicate entries in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CATEGORICAL COLUMNS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols[:5]:  # Show first 5 categorical columns\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  Top 5 values:\\n{df[col].value_counts().head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a6ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"NUMERICAL COLUMNS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb6106f",
   "metadata": {},
   "source": [
    "## 6. Basic Statistical Summary\n",
    "\n",
    "Descriptive statistics for numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6122f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATA QUALITY ISSUES - COLUMNS REQUIRING CLEANING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cleaning_needed = []\n",
    "\n",
    "# Check each column for common data quality issues\n",
    "for col in df.columns:\n",
    "    issues = []\n",
    "    \n",
    "    # Skip if all null\n",
    "    if df[col].isnull().all():\n",
    "        issues.append(\"All values are NULL\")\n",
    "    \n",
    "    # Check for string contamination in numeric-looking columns\n",
    "    if df[col].dtype == 'object':\n",
    "        sample_values = df[col].dropna().head(10).tolist()\n",
    "        \n",
    "        # Check for currency symbols\n",
    "        if any(pd.notna(val) and any(sym in str(val) for sym in ['$', '‚Ç¨', '¬£', '‚Çπ', 'Rs', 'USD']) for val in sample_values):\n",
    "            issues.append(\"Contains currency symbols\")\n",
    "        \n",
    "        # Check for 'km' string (mileage)\n",
    "        if any(pd.notna(val) and 'km' in str(val).lower() for val in sample_values):\n",
    "            issues.append(\"Contains 'km' string\")\n",
    "        \n",
    "        # Check for 'cc' string (engine size)\n",
    "        if any(pd.notna(val) and 'cc' in str(val).lower() for val in sample_values):\n",
    "            issues.append(\"Contains 'cc' string\")\n",
    "        \n",
    "        # Check for percentage signs\n",
    "        if any(pd.notna(val) and '%' in str(val) for val in sample_values):\n",
    "            issues.append(\"Contains percentage signs\")\n",
    "        \n",
    "        # Check for comma separators in numbers\n",
    "        if any(pd.notna(val) and ',' in str(val) and str(val).replace(',', '').replace('.', '').isdigit() for val in sample_values):\n",
    "            issues.append(\"Contains comma separators\")\n",
    "        \n",
    "        # Check for mixed data types\n",
    "        if df[col].dropna().apply(type).nunique() > 1:\n",
    "            issues.append(\"Mixed data types\")\n",
    "        \n",
    "        # Check for whitespace issues\n",
    "        if any(pd.notna(val) and (str(val).startswith(' ') or str(val).endswith(' ')) for val in sample_values):\n",
    "            issues.append(\"Leading/trailing whitespace\")\n",
    "    \n",
    "    # Store findings\n",
    "    if issues:\n",
    "        cleaning_needed.append({\n",
    "            'Column': col,\n",
    "            'Current_Type': str(df[col].dtype),\n",
    "            'Issues': ', '.join(issues),\n",
    "            'Sample_Values': str(sample_values[:3])\n",
    "        })\n",
    "\n",
    "# Display cleaning requirements\n",
    "if cleaning_needed:\n",
    "    cleaning_df = pd.DataFrame(cleaning_needed)\n",
    "    print(cleaning_df.to_string(index=False))\n",
    "    print(f\"\\n‚ö†Ô∏è  Total columns needing cleaning: {len(cleaning_needed)}/{len(df.columns)}\")\n",
    "else:\n",
    "    print(\"‚úÖ All columns appear clean!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ac096",
   "metadata": {},
   "source": [
    "## 5. Data Quality Assessment\n",
    "\n",
    "Identify columns requiring cleaning (currency symbols, unit strings, whitespace, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "if len(missing_data) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(missing_data['Column'], missing_data['Missing_Percentage'], color='coral')\n",
    "    plt.xlabel('Missing Percentage (%)', fontsize=12)\n",
    "    plt.ylabel('Column Name', fontsize=12)\n",
    "    plt.title('Missing Values by Column', fontsize=14, fontweight='bold')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "# Filter columns with missing values\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values(\n",
    "    'Missing_Percentage', ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MISSING VALUES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "if len(missing_data) > 0:\n",
    "    print(missing_data.to_string(index=False))\n",
    "    print(f\"\\n‚ö†Ô∏è  Total columns with missing values: {len(missing_data)}/{len(df.columns)}\")\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d94bbb",
   "metadata": {},
   "source": [
    "## 4. Missing Values Analysis\n",
    "\n",
    "Identify and visualize missing data patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types\n",
    "print(\"=\"*80)\n",
    "print(\"DATA TYPES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cfa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data info\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET INFO\")\n",
    "print(\"=\"*80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06bb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 rows\n",
    "print(\"=\"*80)\n",
    "print(\"FIRST 5 ROWS\")\n",
    "print(\"=\"*80)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9619b3",
   "metadata": {},
   "source": [
    "## 3. Initial Data Inspection\n",
    "\n",
    "Display dataset structure, first rows, and column information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data path\n",
    "DATA_PATH = Path(\"../data/raw/car_web_scraped_dataset.csv\")\n",
    "\n",
    "# Check if file exists\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully\")\n",
    "print(f\"üìä Dataset shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78117504",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data (DVC-Tracked)\n",
    "\n",
    "Load the dataset from the DVC-tracked data directory. Verify file existence and display shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5261dd",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "\n",
    "Import required libraries and configure display options for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b8072",
   "metadata": {},
   "source": [
    "# Used Car Dynamic Pricing - Initial EDA\n",
    "\n",
    "**Objective:** Understand the raw scraped dataset structure, identify data quality issues, and plan preprocessing steps.\n",
    "\n",
    "**Dataset:** `data/raw/car_web_scraped_dataset.csv` (tracked with DVC)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
